--- Page 1 ---
Special Participation A
hw2.pdf
PDF
You are a deep learning tutor. This homework has 
already been released, but we are going to evaluate 
your capabilities for one-shot questions. I will guide you 
towards the correct answer should you make a mistake. 
Please solve the written questions on this worksheet: 1, 
2, and 5. Answer one question one response by 
response (with all its subparts).
Thought for 1m 33s
Question 1 (Optimizers as Penalized Linear Improvement) 
Weâ€™re solving, at each step, an update  (i.e., 
) that minimizes a linearized loss
plus a distance penalty. 
(a) Euclidean (squared 
) penalty 
Problem:
This is a convex quadratic. Take gradient w.r.t. 
 and set to zero:
So the update is:
hw2
u
Î”Î¸â‹†
hw2
â„“
â€‹2
hw2
u = arg
â€‹ g Î”Î¸ +
Î”Î¸
min
âŠ¤
â€‹âˆ¥Î”Î¸âˆ¥
â€‹.
Î±
1
2
2
Î”Î¸
âˆ‡
â€‹
g Î”Î¸ +
â€‹âˆ¥Î”Î¸âˆ¥
â€‹
=
Î”Î¸ ( âŠ¤
Î±
1
2
2)
g +
â€‹Î”Î¸ =
Î±
2
0
â‡’Î”Î¸ =
â‹†
âˆ’
â€‹g.
2
Î±
Î±
ðŸš€ Powered by ChatGPT Exporter
1 / 8


--- Page 2 ---
Optimizer recovered: vanilla gradient descent / SGD step (just with learning rate
).
(b) 
 penalty 
Problem as written:
Let 
. For a fixed , the best (most loss-decreasing) choice is to push every
coordinate to the boundary with the sign opposite the gradient:
which gives
So the objective becomes
From this:
If 
, the minimum is at 
 
.
If 
, the objective is unbounded below as 
 (no finite minimizer).
If 
, any 
 with 
 ties.
Direction-wise, the solution (when itâ€™s finite/meaningful) is the sign direction
, i.e. the steepest-descent direction under an 
 notion of step sizeâ€”this is
the idea behind signSGD / sign-based updates.
(If the intended penalty was the squared version 
 to guarantee a finite
optimum, then youâ€™d get 
 and 
, which is an explicit
sign-based optimizer.)
u = âˆ’
â€‹ g.
2
Î±
Î±/2
â„“
â€‹
âˆž
hw2
u = arg
â€‹ g Î”Î¸ +
Î”Î¸
min
âŠ¤
â€‹âˆ¥Î”Î¸âˆ¥
â€‹.
Î±
1
âˆž
r = âˆ¥Î”Î¸âˆ¥
â€‹
âˆž
r
Î”Î¸
â€‹ =
i
âˆ’r sign(g
â€‹),
i
g Î”Î¸ =
âŠ¤
âˆ’r
âˆ£g
â€‹âˆ£=
i
âˆ‘
i
âˆ’râˆ¥gâˆ¥
â€‹,
âˆ¥Î”Î¸âˆ¥
â€‹ =
1
âˆž
r.
Ï•(r) = âˆ’râˆ¥gâˆ¥
â€‹ +
1
â€‹r =
Î±
1
r
â€‹ âˆ’âˆ¥gâˆ¥
â€‹
.
(Î±
1
1)
âˆ¥gâˆ¥
â€‹ <
1
â€‹Î±
1
r = 0 â‡’u = 0
âˆ¥gâˆ¥
â€‹ >
1
â€‹Î±
1
r â†’âˆž
âˆ¥gâˆ¥
â€‹ =
1
â€‹Î±
1
r â‰¥0
Î”Î¸ = âˆ’r sign(g)
âˆ’sign(g)
â„“
â€‹
âˆž
â€‹âˆ¥Î”Î¸âˆ¥
â€‹
Î±
1
âˆž
2
r =
â‹†
â€‹âˆ¥gâˆ¥
â€‹
2
Î±
1
u
â€‹ =
i
âˆ’
â€‹âˆ¥gâˆ¥
â€‹ sign(g
â€‹)
2
Î±
1
i
ðŸš€ Powered by ChatGPT Exporter
2 / 8
Document parser reads off L1 penalty instead of 
L2 penalty, but catches ambiguity and provides 
correct result anyways 


--- Page 3 ---
If you want, Iâ€™ll move on to Question 2 next (all subparts) in the next message.
Î±1â€‹âˆ¥Î”Î¸âˆ¥âˆž
Correct! I think you had a parsing error here, because 
this indeed was the desired penalty. However, you got 
the right answer in the end. Let's move on to Question 
2.
Thought for 1m 4s
Question 2 (Optimizers and their convergence) 
Let 
 and 
. 
Then 
.
(a) Vanilla SGD ( 
 ) 
From 
, every update is proportional to , so 
. Write 
. At
convergence we need 
, i.e.
So SGD converges to
(b) Simplified Adam 
 
hw2
a = [1, 0.1, 0.01]âŠ¤
f(Î¸) = (1 âˆ’a Î¸)
âŠ¤
2
hw2
âˆ‡f(Î¸) = âˆ’2(1 âˆ’a Î¸) a
âŠ¤
M
â€‹ =
t
I,Â  Î±
â€‹ =
t
Î±
hw2
Î¸
â€‹ =
0
0
a
Î¸
â€‹ âˆˆ
t
span(a)
Î¸
â€‹ =
t
c
â€‹a
t
a Î¸ =
âŠ¤
1
a (ca) =
âŠ¤
c âˆ¥aâˆ¥
â€‹ =
2
2
1
â‡’
c =
â€‹.
âˆ¥aâˆ¥
â€‹2
2
1
âˆ¥aâˆ¥
â€‹ =
2
2
1 +
2
0.1 +
2
0.01 =
2
1.0101.
â€‹
Î¸
â€‹ =
â€‹[1, 0.1, 0.01]
â‰ˆ[0.99000099, 0.099000099, 0.0099000099] .
SGD
â‹†
1.0101
1
âŠ¤
âŠ¤
O
hw2
ðŸš€ Powered by ChatGPT Exporter
3 / 8


--- Page 4 ---
Here 
 example per epoch, so the â€œmean squared gradient over the epochâ€ for
coordinate  is just 
. Thus
But 
, and all entries of  are positive, so all coordinates share the
same sign. Therefore the iterate stays on the line 
. At convergence we
must satisfy 
:
So (with step sizes 
 chosen to actually converge) Adam 
 converges to
\boxed{\theta_{O}^\star = \frac{1}{1.11}[1,\;1,\;1]^\top \approx
[0.9009009,\;0.9009009,\;0.9009009]^\top.} \] :contentReference[oaicite:4]
{index=4} --- #### (c) Feature rescale to unit second moment â†’ SGD â†’ map back
:contentReference[oaicite:5]{index=5} With one training point, the (empirical) second
moment of feature \(i\) is \(a_i^2\). Rescaling to unit second moment means divide
feature \(i\) by \(|a_i|\), giving a rescaled feature vector \[ z = \left[\frac{1}
{1},\frac{0.1}{0.1},\frac{0.01}{0.01}\right]^\top = [1,1,1]^\top.
Run SGD from 0 on 
. By the same logic as part (a), it converges to
Mapping back to original coordinates uses 
 (here 
), so 
:
If you want, Iâ€™ll do Question 5 next (all its subparts) in the next response.
n = 1
i
g
â€‹
t,i
2
M
â€‹ =
t
diag
â€‹,
â€‹,
â€‹
â‡’
(âˆ£g
â€‹âˆ£
t,1
1
âˆ£g
â€‹âˆ£
t,2
1
âˆ£g
â€‹âˆ£
t,3
1
)
M
â€‹g =
t t
sign(g
â€‹)Â (elementwise).
t
g
â€‹ =
t
âˆ’2(1 âˆ’a Î¸
â€‹)a
âŠ¤t
a
Î¸
â€‹ =
t
v
â€‹[1, 1, 1]
t
âŠ¤
a Î¸ =
âŠ¤
1
v(1 + 0.1 + 0.01) = v â‹…1.11 = 1 â‡’v =
â€‹.
1.11
1
Î±
â€‹t
O
(1 âˆ’z Ï•)
âŠ¤
2
Ï• =
â‹†
â€‹z =
âˆ¥zâˆ¥
â€‹2
2
1
â€‹[1, 1, 1] .
3
1
âŠ¤
Ï•
â€‹ =
i
âˆ£a
â€‹âˆ£Î¸
â€‹
i
i
a
â€‹ >
i
0
Î¸
â€‹ =
i
Ï•
â€‹/a
â€‹
i
i
â€‹
Î¸ =
,Â 
â€‹,Â 
â€‹
=
â€‹,Â 
â€‹,Â 
â€‹
â‰ˆ[0.3333,Â  3.3333,Â  33.3333] .
â‹†
[ 1
1/3
0.1
1/3
0.01
1/3 ]
âŠ¤
[3
1
3
10
3
100]
âŠ¤
âŠ¤
ðŸš€ Powered by ChatGPT Exporter
4 / 8
LaTeX error! But correct result.


--- Page 5 ---
\\boxed{\\theta\_{O}^\\star = \\frac{1}{1.11}\[1,\\;1,\\;1\]^\\top \\approx \
[0.9009009,\\;0.9009009,\\;0.9009009\]^\\top.} \\\] :contentReference\[oaicite:4\]{index=4}
--- #### (c) Feature rescale to unit second moment â†’ SGD â†’ map back :contentReferencâ€¦
You had a LaTeX error! But your answers are otherwise 
correct. Can you rewrite your answer for 2) before we 
move on?
Question 2 (rewritten cleanly)
Given
the gradient is
(a) Vanilla SGD 
Starting from 
, every update is a scalar multiple of , so 
. Write
. At convergence, we need 
, so
Compute
Therefore
(b) Simplified Adam 
a =
â€‹
â€‹
â€‹,
f(Î¸) =
1
0.1
0.01
(1 âˆ’a Î¸) ,
âŠ¤
2
âˆ‡f(Î¸) = âˆ’2(1 âˆ’a Î¸) a.
âŠ¤
(M
â€‹ =
t
I,Â  Î±
â€‹ =
t
Î±)
Î¸
â€‹ =
0
0
a
Î¸
â€‹ âˆˆ
t
span(a)
Î¸
â€‹ =
t
c
â€‹a
t
a Î¸ =
âŠ¤
1
a (ca) =
âŠ¤
câˆ¥aâˆ¥
â€‹ =
2
2
1
â‡’
c =
â€‹.
âˆ¥aâˆ¥
â€‹2
2
1
âˆ¥aâˆ¥
â€‹ =
2
2
1 +
2
0.1 +
2
0.01 =
2
1 + 0.01 + 0.0001 = 1.0101.
Î¸
â€‹ =
SGD
â‹†
â€‹
â€‹
â€‹
â€‹ â‰ˆ
1.0101
1
1
0.1
0.01
â€‹
â€‹
â€‹.
0.99000099
0.099000099
0.0099000099
O
ðŸš€ Powered by ChatGPT Exporter
5 / 8


--- Page 6 ---
With one data point per epoch, the â€œmean squared gradient over the epochâ€ in
coordinate  is just 
, so
which implies elementwise
But
and all entries of  are positive, so all coordinates of 
 share the same sign. Hence
each step moves along the 
 direction, meaning 
 with 
.
At convergence we need 
:
So
(c) Rescale features to unit second moment, run SGD, then map back
With one example, the empirical second moment of feature  is 
. To make each
feature have unit second moment, rescale coordinate  by dividing by 
. The
rescaled feature vector is
Run SGD from 0 on 
. By the same reasoning as (a), it converges to
i
g
â€‹
t,i
2
M
â€‹ =
t
diag
â€‹,
â€‹,
â€‹
,
(âˆ£g
â€‹âˆ£
t,1
1
âˆ£g
â€‹âˆ£
t,2
1
âˆ£g
â€‹âˆ£
t,3
1
)
(M
â€‹g
â€‹)
â€‹ =
t t i
â€‹ =
âˆ£g
â€‹âˆ£
t,i
g
â€‹
t,i
sign(g
â€‹).
t,i
g
â€‹ =
t
âˆ’2(1 âˆ’a Î¸
â€‹) a,
âŠ¤t
a
g
â€‹t
[1, 1, 1]âŠ¤
Î¸
â€‹ =
t
v
â€‹1
t
1 = [1, 1, 1]âŠ¤
a Î¸ =
âŠ¤
1
a (v1) =
âŠ¤
v(1 + 0.1 + 0.01) = v â‹…1.11 = 1
â‡’
v =
â€‹.
1.11
1
Î¸
â€‹ =
O
â‹†
â€‹
â€‹
â€‹
â€‹ â‰ˆ
1.11
1
1
1
1
â€‹
â€‹
â€‹.
0.9009009
0.9009009
0.9009009
i
a
â€‹i
2
i
âˆ£a
â€‹âˆ£
i
z =
â€‹
â€‹
â€‹ =
1/1
0.1/0.1
0.01/0.01
â€‹
â€‹
â€‹.
1
1
1
(1 âˆ’z Ï•)
âŠ¤
2
Ï• =
â‹†
â€‹z =
âˆ¥zâˆ¥
â€‹2
2
1
â€‹
â€‹
â€‹
â€‹.
3
1
1
1
1
ðŸš€ Powered by ChatGPT Exporter
6 / 8


--- Page 7 ---
Mapping back: since we scaled features by 
 and here 
, the
parameter relationship is 
, so 
. Therefore
Ready for Question 5.
z
â€‹ =
i
a
â€‹/âˆ£a
â€‹âˆ£
i
i
a
â€‹ >
i
0
Ï•
â€‹ =
i
a
â€‹Î¸
â€‹
i i
Î¸
â€‹ =
i
Ï•
â€‹/a
â€‹
i
i
Î¸ =
â‹†
â€‹
â€‹
â€‹ =
(1/3)/1
(1/3)/0.1
(1/3)/0.01
â€‹
â€‹
â€‹ â‰ˆ
1/3
10/3
100/3
â€‹
â€‹
â€‹.
0.3333
3.3333
33.3333
Looks good. Let's move on to Question 5, then.
Thought for 45s
Question 5 (Analyzing Distributed Training) 
Assume  workers, model has  parameters, and  divisible by . The filled-in
communication costs per iteration are:
Paradigm
Total # messages sent
Size of each message
All-to-All
Parameter Server
Ring All-Reduce
Explanation (one-liners):
All-to-All: each worker sends its full gradient (size ) to each of the other 
workers 
 sends total.
Parameter Server: each worker sends a gradient to the server and receives
updated weights back 
 messages, each of size .
Ring All-Reduce: gradients are split into  chunks of size 
; there are 
passes and each worker sends one chunk per pass 
 messages of
size 
. 
hw2
n
p
p
n
n(n âˆ’1)
p
2n
p
n â‹…2(n âˆ’1)
p/n
p
n âˆ’1
â‡’n(n âˆ’1)
â‡’2n
p
n
p/n
2(n âˆ’1)
â‡’n â‹…2(n âˆ’1)
p/n
hw2
ðŸš€ Powered by ChatGPT Exporter
7 / 8


--- Page 8 ---
Perfect!
Nice â€” if you have any follow-ups (e.g., deriving bandwidth/time per iteration under a
network model, or comparing asymptotics), throw them at me.
ðŸš€ Powered by ChatGPT Exporter
8 / 8
